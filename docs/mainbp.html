<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>mainBP</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/master/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">JAGS_LFO</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/franfram/JAGS_LFO">
    <span class="fa fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">mainBP</h1>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span> workflowr <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2021-10-25
</p>
<p>
<strong>Checks:</strong> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 1 <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> 1
</p>
<p>
<strong>Knit directory:</strong> <code>JAGS_LFO/</code> <span class="glyphicon glyphicon-question-sign" aria-hidden="true" title="This is the local directory in which the code in this file was executed."> </span>
</p>
<p>
This reproducible <a href="http://rmarkdown.rstudio.com">R Markdown</a> analysis was created with <a
  href="https://github.com/jdblischak/workflowr">workflowr</a> (version 1.6.2). The <em>Checks</em> tab describes the reproducibility checks that were applied when the results were created. The <em>Past versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguncommittedchanges"> <span class="glyphicon glyphicon-exclamation-sign text-danger" aria-hidden="true"></span> <strong>R Markdown file:</strong> uncommitted changes </a>
</p>
</div>
<div id="strongRMarkdownfilestronguncommittedchanges" class="panel-collapse collapse">
<div class="panel-body">
<p>The R Markdown is untracked by Git. To know which version of the R Markdown file created these results, you’ll want to first commit it to the Git repo. If you’re still working on the analysis, you can ignore this warning. When you’re finished, you can run <code>wflow_publish</code> to commit the R Markdown file and build the HTML.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomfranframJAGSLFOtreedbab5d599de6bbe2e8a43370a690018279cd557btargetblankdbab5d5a"> <span class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> <strong>Repository version:</strong> <a href="https://github.com/franfram/JAGS_LFO/tree/dbab5d599de6bbe2e8a43370a690018279cd557b" target="_blank">dbab5d5</a> </a>
</p>
</div>
<div id="strongRepositoryversionstrongahrefhttpsgithubcomfranframJAGSLFOtreedbab5d599de6bbe2e8a43370a690018279cd557btargetblankdbab5d5a" class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development and connecting the code version to the results is critical for reproducibility.
</p>
<p>
The results in this page were generated with repository version <a href="https://github.com/franfram/JAGS_LFO/tree/dbab5d599de6bbe2e8a43370a690018279cd557b" target="_blank">dbab5d5</a>. See the <em>Past versions</em> tab to see a history of the changes made to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for the analysis have been committed to Git prior to generating the results (you can use <code>wflow_publish</code> or <code>wflow_git_commit</code>). workflowr only checks the R Markdown file, but you know if there are other scripts or data files that it depends on. Below is the status of the Git repository when the results were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .Rhistory
    Ignored:    .Rproj.user/

Untracked files:
    Untracked:  an autoregresive model with latent variables
    Untracked:  analysis/images/
    Untracked:  analysis/main.Rmd
    Untracked:  analysis/mainbp.Rmd
    Untracked:  analysis/test.Rmd
    Untracked:  analysis/vehtari-paper_notes.Rmd

Unstaged changes:
    Modified:   analysis/info_theory.rmd

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not included in this status report because it is ok for generated content to have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">
<p>
There are no past versions. Publish this analysis with <code>wflow_publish()</code> to start tracking its development.
</p>
<hr>
</div>
</div>
</div>
<p>haven’t read on last pass of info_theory.Rmd:</p>
<ul>
<li><p>anything outside of ben lambert or gelmans stuff</p></li>
<li><p>really anything from kl divergence outside the general idea that ben lambert gives or the part that gelman names it briefly.</p></li>
</ul>
<p>index:</p>
<ul>
<li><p>why are we interested in prediction accuracy? (good paragraph from gelman).</p></li>
<li><p>3 or 2. how do we measure predictive accuracy (general probability scoring rules, then logscores). How we measure predictive accuracy of our bayesian model taking into account the two sources of uncertainty.</p></li>
</ul>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>Kullback-Liebler Divergence</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p>A few properties of the KL-Divergence:</p>
<ul>
<li><p>It is always non-negative <span class="math inline">\(D_{KL}(P || Q) \geq 0\)</span>, a result known as “Gibbs inequality”, with <span class="math inline">\(D_{KL}(P || Q)\)</span> equal to zero iff <span class="math inline">\(P = Q\)</span> almost everywhere.</p></li>
<li><p>No upper-bound exists for the general case. However, it is shown that if <span class="math inline">\(P\)</span> and <span class="math inline">\(Q\)</span> are two discrete probability distributions built by distributing the same discrete quantity, then the maximum value of <span class="math inline">\(D_{KL}(P || Q)\)</span> can be calculated.</p></li>
<li><p>KL divergence remains well-defined for continuous distributions, and furthermore is invariant under parameter transformations.</p></li>
<li><p>KL divergence is additive for independent distributions, in much the same way as Shannon entropy.</p></li>
</ul>
<p>Not understood deeply enough yet to give a thorough explanation on this topic, more on this later.</p></td>
</tr>
<tr class="even">
<td></td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>Prior vs Posterior Predictive distribution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p>It’s important to note that we have both a <strong>prior</strong> and a <strong>posterior</strong> predictive distribution.</p>
<p>The <strong>prior</strong> predictive distribution is just the distribution of data which we think we are going to obtain before we actually see the data <span class="math inline">\(y\)</span>, thus the <span class="math inline">\(prior\ predictive\ distribution = p(y)\)</span>. This is based on our prior sort of knowledge about the situation. How can we calculate it? the idea is that we’re trying to obtain is the probability of our data <span class="math inline">\(y\)</span>. This is a marginal probability and we know that we can get to a marginal probability by integrating out all dependences, in this case, <span class="math inline">\(\theta\)</span> of our joint probability <span class="math inline">\(p(y, \theta)\)</span> across all the range of values theta can take (<span class="math inline">\(\theta \in \Theta\)</span>) . So by integrating this out we’re removing all this theta dependence and we’re just left with the marginal probability <span class="math inline">\(p(y)\)</span>. So</p>
<p><span class="math display">\[
p(y) = \int_{\theta \in \Theta} p(y,\theta)d\theta
\]</span></p>
<p>and through the product rule of probability, which states that <span class="math inline">\(p(A, B) = p(A|B)p(B)\)</span>, we get:</p>
<p><span class="math display">\[
p(y) = \int_{\theta \in \Theta} p(y,\theta)d\theta = \int_{\theta \in \Theta} p(y|\theta)p(\theta)d\theta.
\]</span></p>
<p>where <span class="math inline">\(p(y|\theta)\)</span> is the likelihood and <span class="math inline">\(p(\theta)\)</span> the prior.</p>
<p>And with the posterior predictive distribution we essentially mean what value of data we would expect to obtain (that is, what our model would suggest after using the first observed data for fitting said model) if were to repeat the observation. We will call this new observation of data, <span class="math inline">\(y&#39;\)</span>. So how do we calculate this posterior predictive distribution? The idea is that we are trying to calculate the probability of certain value of the new data <span class="math inline">\(y&#39;\)</span> given that we have observed the current data <span class="math inline">\(y\)</span> (the one used to fit the model), that is, <span class="math inline">\(p(y&#39;|y)\)</span>. We can get this conditional probability by integrating out the joint probability of <span class="math inline">\(y&#39;\)</span> and <span class="math inline">\(\theta\)</span>, acrross al range of theta (<span class="math inline">\(\Theta\)</span>). Thus,</p>
<p><span class="math display">\[
p(y&#39;|y) = \int_{\theta \in \Theta} p(y&#39;,\theta |y)d\theta
\]</span></p>
<p>and through the chainrule of probability?, which states that <span class="math inline">\(p(A, B |C) = p(A|B, C) p(B|C)\)</span>, we get:</p>
<p><span class="math display">\[
p(y&#39;|y) = \int_{\theta \in \Theta} p(y&#39;,\theta |y)d\theta = \int_{\theta \in \Theta} p(y&#39;|\theta, y) p(\theta|y)d\theta
\]</span></p>
<p>and normally when you condition on <span class="math inline">\(\theta\)</span>, our new observation <span class="math inline">\(y&#39;\)</span> is independent of the current observation <span class="math inline">\(y\)</span> (that is, once you know <span class="math inline">\(\theta\)</span>, <span class="math inline">\(y\)</span> doesn’t provide any extra information about <span class="math inline">\(y&#39;\)</span> ) and thus we can eliminate the dependency of <span class="math inline">\(y&#39;\)</span> on <span class="math inline">\(y\)</span>, so we get:</p>
<p><span class="math display">\[
p(y&#39;|y) = \int_{\theta \in \Theta} p(y&#39;|\theta) p(\theta|y)d\theta
\]</span></p>
<p>where <span class="math inline">\(p(y&#39;|\theta)\)</span> is the likelihood and <span class="math inline">\(p(\theta|y)\)</span> is the posterior distribution.</p></td>
</tr>
<tr class="even">
<td></td>
</tr>
</tbody>
</table>
<p>Given a posterior distribution <span class="math inline">\(p(\theta | \pmb{x})\)</span>, we can produce a posterior predictive distribution, which for a single new data point equals <span class="math inline">\(p(x^{new} | \pmb{x})\)</span> (m’ more detail on this on here NOTE), and this just tells us what is our sort of best prediction or distribution which ecompasses what we think about predictions for the next data point given that we have observed a data vector <span class="math inline">\(\pmb{x}\)</span>. This distribution <span class="math inline">\(p(x^{new} | \pmb{x})\)</span> is an approximation to some unkown true data generating process which, we can call <span class="math inline">\(f(x^{new})\)</span>. Ideally, if we knew what the distribution <span class="math inline">\(f(x^{new})\)</span> was, we could compare it with our posterior predictive distribution <span class="math inline">\(p(x^{new} | \pmb{x})\)</span>. The best way we could compare this two distributions (if we knew both of them), is with what is called the Kullback-Leibler divergence (<span class="math inline">\(D_{KL}\)</span>, also known as “relative entropy”), which is just a general measure of the difference between two distributions.</p>
<ul>
<li>2 or 3. idea of posterior predictive distribution vs true but unknown distribution. KL divergence, general idea, some properties (more things in a box). Maybe in another box the note that we have both the prior and a posterior predictive distribution.</li>
</ul>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>Information Criteria (AIC, DIC, WAIC).</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>general thing of what they aim to do (measure predictive accuracy) using what (data used to fit the model) and how they do it (some sort of measure of the log likelihood minus a penalty).</td>
</tr>
<tr class="even">
<td></td>
</tr>
</tbody>
</table>
<p>what is IC doing?</p>
<ul>
<li><p>In the case of a hierarchical model, What are we trying to predict? in group or another group? differences in the posterior predictive distribution and why we are not bothered by the non-uniqueness of the posterior predictive distribution.</p></li>
<li><p>what should we do if we are doing LOO-CV. (for illustration and to stand the difference with LFO-CV).</p></li>
</ul>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th>JAGS output and the logdensity functions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p>Straight from JAGS user manual 2017 (<a href="https://sourceforge.net/projects/mcmc-jags/files/Manuals/4.x/" class="uri">&lt;https://sourceforge.net/projects/mcmc-jags/files/Manuals/4.x/&gt;</a>).</p>
<p>START OF EXCERPT</p>
<p>6.3. Functions associated with distribution</p>
<p>All distribution sin JAGS have a log density function associated withi them. For example, if variable <span class="math inline">\(x\)</span> has a normal distribution with mean <span class="math inline">\(mu\)</span> and precision <span class="math inline">\(tau\)</span>:</p>
<p><span class="math display">\[
x ~ \sim dnorm(mu, tau)
\]</span></p>
<p>then the log density of <span class="math inline">\(x\)</span> is given by</p>
<p><span class="math display">\[
ldx \leftarrow logdensity.norm(x, mu, tau)
\]</span></p>
<p>In general, if “dfoo” is the name of a distribution then the associated log density function is “logdensity.foo”. The first argument of the log-density function is the sample value at which the log-density is evaluated and the remaining arguments are the parameters of the distribution <!--# posterior parameters i'd like to think -->.</p>
<p>FINISH OF EXCERPT</p>
<p>Maybe say that u r not entirely sure if this is giving u what u need (the “posterior” log likelihood or posterior predictive density), and that u still need to check JAGS codebase to make sure because it’s not clearly explained in the user manual.</p>
<p>search for the first time “density” comes up in the manual</p></td>
</tr>
<tr class="even">
<td></td>
</tr>
</tbody>
</table>
<ul>
<li><p>also here state what do we need for computing loocv with the loo package and also check the loo package for how to use with different prediction objectives and thus predictive distributions. (a matrix with log likelihoods?; state the problem of jags documentation that it says it can give you the loglikelihood (which is what the predictive distribution is sometimes called) but it’s not specified if its giving you the prior or posterior distribution. to solve this, see if the chapter where that definition is gives you a hint, or can you run the model without data to see if the log likelihood appears? or maybe use different data but same priors and see if there’s a difference between the matrix jags retrieves, maybe add a random value to each data point and check if the logposterior is the same, but the problem here is that there’s always some sampling variability, or is the set.seed what completely avoids this? maybe run the model many times with the same seed, save the log likelihoods and then compare them with that package to compare datasets.).</p></li>
<li><p>what should we do if we are doing LFO-CV.</p></li>
</ul>
<table style="width:28%;">
<colgroup>
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th>log-sum-exp trick</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
</tr>
<tr class="even">
<td></td>
</tr>
</tbody>
</table>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
http://docs.mathjax.org/en/latest/configuration.html.  This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
